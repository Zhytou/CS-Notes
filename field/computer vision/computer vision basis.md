# 计算机视觉基础

- [计算机视觉基础](#计算机视觉基础)
  - [特征检测与描述 Detector and Descriptor](#特征检测与描述-detector-and-descriptor)
    - [边缘检测](#边缘检测)
      - [边缘检测算子](#边缘检测算子)
      - [滤波器基础](#滤波器基础)
      - [Canny算法](#canny算法)
    - [角点检测](#角点检测)
      - [Harris](#harris)
      - [Harris-Laplace](#harris-laplace)
    - [斑点检测](#斑点检测)
      - [LoG](#log)
      - [DoG](#dog)
    - [特征描述](#特征描述)
      - [SIFT](#sift)
      - [SURF](#surf)
      - [HoG](#hog)
  - [拟合与对齐 Fitting and Alignment](#拟合与对齐-fitting-and-alignment)
    - [霍夫变换](#霍夫变换)
      - [霍夫直线变换](#霍夫直线变换)
      - [霍夫圆变换](#霍夫圆变换)
    - [RANSAC](#ransac)
    - [应用——图像融合](#应用图像融合)
  - [聚类和分割 Clustering and Segmentation](#聚类和分割-clustering-and-segmentation)
    - [聚类分析](#聚类分析)
      - [Hierarchical Clustering](#hierarchical-clustering)
      - [K-means](#k-means)
      - [均值漂移](#均值漂移)
    - [图像分割](#图像分割)
      - [Watershed算法](#watershed算法)
  - [分类和识别 Categorization and Object Recognition](#分类和识别-categorization-and-object-recognition)
    - [人脸识别](#人脸识别)
      - [PCA](#pca)
      - [LDA](#lda)
      - [Eigenface and Fisherface](#eigenface-and-fisherface)
    - [基于机器学习的分类器](#基于机器学习的分类器)
      - [KNN](#knn)
      - [SVM](#svm)
      - [决策树](#决策树)
  - [检测和追踪 Detection and Tracking](#检测和追踪-detection-and-tracking)
    - [目标检测](#目标检测)
      - [VJ and HoG+SVM](#vj-and-hogsvm)
      - [DPM](#dpm)
      - [R-CNN](#r-cnn)
      - [YOLO](#yolo)
    - [目标追踪](#目标追踪)
      - [Lucas-Kanade光流法](#lucas-kanade光流法)
      - [卡尔曼滤波](#卡尔曼滤波)
      - [核方法](#核方法)
      - [相关滤波方法](#相关滤波方法)
  - [其他](#其他)
    - [连通域分析](#连通域分析)
    - [阈值处理](#阈值处理)
  - [参考](#参考)

## 特征检测与描述 Detector and Descriptor

在计算机视觉领域中，常见的[特征](https://en.wikipedia.org/wiki/Feature_(computer_vision))可分为三类，分别是：

- Edge
- Corner/Interest Points/Key Points
- Blob/Region Of Interest Points

### 边缘检测

在图像中，一个物体的边缘或者轮廓往往会发生灰度值突变。因此，可以采用计算其灰度值导数（即相邻像素灰度差分）的方式检测边缘。一个最简单的边缘检测步骤如下：

- 将彩色图像转为灰度图像；
- 使用边缘检测算子计算灰度值变换率和变换方向，即求导得出梯度（方向和大小）；
- 使用单一阈值将梯度阈值进行二值化，得到二值边缘图。

#### 边缘检测算子

边缘检测算子也就是在检测边缘中用于计算灰度值梯度的运算符。它可依据求导次数分为一阶导数算子和二阶导数算子。当计算图像边缘的导数时，一阶导数通常产生较粗的边缘，即边缘处导数一直非零；而二阶导数则产生两个有间距的双边缘（由零分开，单像素宽）。关于二者区别，具体如下图所示。

![一阶导数和二阶导数的区别](../img/computer_vision_differential.png)

常见的边缘检测算子包括：

- **Roberts算子**：利用对角相邻像素点进行卷积计算梯度。
- **Sobel算子**：该算子包含两组3x3的矩阵，分别为横向及纵向。将之与图像作平面卷积，即按所示方程式计算：
  $$
  G_x*A = [[1, 0, -1], [2, 0, -2], [1, 0, -1]]*A = [f(x+1, y-1)+2*f(x+1, y)+f(x+1, y+1)]-[f(x-1, y-1)+2*f(x-1, y)+f(x-1, y+1)]
  G_y*A = [[1, 2, 1], [0, 0, 0], [-1, -2, -1]]*A = [f(x-1, y+1)+2*f(x, y+1)+f(x+1, y+1)]-[f(x-1, y-1)+2*f(x, y-1)+f(x+1, y-11)]
  $$
- **Prewitt算子**：原理与Sobel类似，但使用不同的卷积核。

#### 滤波器基础

事实上，这些用于边缘检测的算子正是数字图像处理中的锐化滤波器。它基于卷积差分，能够增强边界和突出细节。而与之对应的正是基于卷积求和的平滑滤波器，二则一起组成了空间域滤波器。其中，平滑滤波器可按计算方法分为平滑线性滤波器和统计排序（非线性）滤波器，包括：

- **均值滤波器**是最简单的线性滤波器，它通过计算像素邻域内的像素值平均值来替换中心像素的值。这有助于消除噪声，但可能导致边缘模糊。
- **加权线性滤波器**使用不同权重的邻域像素值进行滤波，权重通常随着距离中心像素的增加而减小。
- **高斯滤波器**是加权线性滤波器的一个例子，其权重由高斯函数决定，对中心像素赋予最大权重，对远离中心的像素赋予较小权重，这在平滑图像的同时能较好地保持边缘。
- **中值滤波器**是一种非线性滤波器，它将中心像素替换为其邻域像素排序后的中值。这种方法对椒盐噪声有很好的去除效果，同时能较好地保护边缘。

#### Canny算法

尽管使用边缘检测算子得到灰度值梯度之后，可以直接用其梯度幅度二值化得到边缘二值图像，但是这样做有两个缺点：

- 没有充分利用梯度的方向信息；
- 仅简单使用单阈值进行处理。

因此，Canny边缘检测算法被提出了。它针对上面两个缺点提出了改进，分别是：

- 基于边缘梯度方向的非极大值抑制；
- 双阈值的滞后阈值处理。

具体来说，Canny算法的步骤为：

- 噪声抑制：在梯度计算之前，Canny算法先进行高斯滤波以平滑图像，有效地减少了噪声对边缘检测的影响。
- 非极大值抑制：Canny算法在梯度幅值图上进行非极大值抑制，确保边缘的精确定位。简单来说，它会去寻找像素点局部最值。在每一点上，领域中心与沿着其对应的梯度方向的两个像素相比，若中心像素为最大值，则保留；否则中心置0。这样可以抑制非极大值，保留局部梯度最大的点，以细化边缘。
- 双阈值检测：Canny算法使用双阈值检测来区分强边缘和弱边缘。
  - 如果某一像素位置的幅值超过高阈值，该像素为强边缘像素，将会被保留。
  - 如果某一像素位置的幅值小于低阈值，该像素被排除。
  - 如果某一像素位置的幅值在两个阈值之间，该像素为弱边缘像素，按和强边缘的连通性选择是否保留。
- 边缘连接：Canny算法根据弱边缘和强边缘的连通性选择是否保留弱边缘。

### 角点检测

在计算机视觉领域中，关键点，也被称为兴趣点或角点，是指图像中独特且重要的点或特征。它们的特点是，在任意方向上的一个微小变化造成其灰度的剧烈变化。一般来说，角点通常位于两条或多条边缘的交汇处。

#### Harris

**基本原理**：

Harris角点检测的原理是，使用指定大小的窗口中在图片各个方向上平移，观察窗口内容的相似程度。其判定方法和示例图如下：

- 当沿任意方向窗口内部图像均基本无变化时，判定为Flat；
- 当且仅当沿某方向窗口内部图像基本无变化时，判定为edge；
- 当沿任意方向窗口内部图像均发生变化时，判定为Corner。

![flat、edge、corner图例](https://ooo.0o0.ooo/2017/06/28/5953a445031a0.jpg)

**数学推导**：

当站在数学角度进行严格推导时，该算法使用自相关函数去描述平移后窗口w(x, y)内图片I(x, y)的相似程度，其公式如下：$E(u, v)=\Sigma_x\Sigma_yw(x, y) [I(x+u, y+v)-I(x, y)]^2$。

当平移量u和v很小时，可以对E(u, v)进行泰勒展开，其公式如下：$E(u, v)=[I(x, y)+uI_x+vI_y-I(x, y)]^2=u^2I_x^2+v^2I_y^2+2uvI_xI_y$。

对于上述自相关函数E(u, v)，可以进一步对其使用特征分解得到特征值$\lambda_1, \lambda_2$，而使用该特征值进行判定的方法如下图。

![特征值判断方法](https://ooo.0o0.ooo/2017/06/28/5953b3774c2f2.png)

然而在实际运用中，无需具体计算特征值，而使用一个量化指标R去判断。该指标的计算方法如下：$R=det(M)-trace(M)^2$。其中det(M)和trace(M)分别为矩阵M的行列式和迹。

- 当R大于零，且其绝对值很大时，为角点；
- 当R小于零，且其绝对值也很大时，为边。

**算法特点**：

- 旋转、平移不变性；
- 图像有偏置时极值点不变；
- 无尺度不变性。 ——> Solution: Harris-Laplace / SIFT

关于Harris角点检测的详细介绍，可以参考博客[图像特征之Harris角点检测](https://senitco.github.io/2017/06/18/image-feature-harris/)。

#### Harris-Laplace

### 斑点检测

斑点是图像中具有一致性特征的区域，这些特征可能是亮度、颜色或者纹理等。一般来说，斑点通常是图像中的局部极值点，即在某个邻域内有显著不同于周围像素的点。斑点检测的目的是找出这些极值点及其所在的区域。

#### LoG

高斯拉普拉斯(Laplacian of Gaussian, LoG)算子是最常见的斑点检测算法。它首先将图片与高斯核进行卷积以平滑影像，然后应用拉普拉斯算子，斑点在拉普拉斯响应达到显著值的点处被检测出来。

#### DoG

高斯差(Differential of Guassian)算子是一种近似LoG的斑点检测算法。它通过计算两个不同标准差的高斯平滑图像的差值来近似LoG的效果。

### 特征描述

> ![What is the difference between feature detectors and feature descriptors?](https://dsp.stackexchange.com/questions/24346/what-is-the-difference-between-feature-detectors-and-feature-descriptors)

#### SIFT

> 关于SIFT算法的详细介绍，可以参考博客[你对SIFT算法了解多少—原理详解与演示](https://blog.csdn.net/DIPDWC/article/details/117605628)。

尺度不变特征变换(Scale Invariant Feature Transform, SIFT)是计算机视觉中一种检测、描述和匹配图像局部特征点的方法，通过在不同的尺度空间中检测极值点或特征点 (Conrner Point, Interest Point) ，提取出其位置、尺度和旋转不变量，并生成特征描述子，最后用于图像的特征点匹配。也就是说，和Harris、FAST这类特征点检测算法相比，SIFT算法不仅能够检测还能够描述进而用于后续的匹配操作，比如图像融合等。

**尺度空间**：

尺度空间(Scale Space)理论描述了图像的模糊程度和人感知其大小的关系。近距离看一个物体和远距离看一个物体，模糊程度是不一样的；从近到远，图像越来越模糊的过程，也是图像的尺度越来越大的过程。一般来说，使用图片金字塔来模拟尺度空间。

**计算流程**：

- 为了提取到不受尺度变换影响的特征，SIFT需要首先生成图片金字塔。具体来说，它采用DoG算子获取高斯差分金字塔。
- 接着，在该金字塔内找到极值点。由于DoG算子是LoG算子的近似，且一般用于Blob检测。因此，这些极值点实际就是图像中较暗或者较亮的斑点。
- 然后，筛选上述选出的极值点，剔除低对比度和不稳定的边缘响应点。
- 接着，确定这些关键点的具体位置，并且计算其在邻域窗口内的梯度幅值和方向。
- 最后，依据关键点位置(x,y)和尺度σ在高斯金字塔上确定采样区域，计算该区域内梯度幅值和方向，并统计具有高度旋转不变性的8邻域梯度直方图。组合8邻域的直方图(4x4矩阵),共计算128维SIFT特征向量

#### SURF

#### HoG

方向梯度直方图(Histogram of Oriented Gradient, HoG)在计算机视觉邻域中一种常用于目标检测(Object Detection)的特征描述器。Navneet Dalal和Bill Triggs于2005年在CVPR发表了使用HoG结合SVM分类器进行行人检测的论文。目前，HoG结合SVM分类器已经被广泛应用于目标检测中。具体来说，HoG首先计算每个像素点的梯度幅值和方向，然后在细分的小区域(Cell)内统计梯度方向直方图，最终构成特征向量。

**计算流程**：

- 首先进行图像预处理，包括灰度化和伽马矫正。因为HoG提取的是纹理特征，颜色信息不起作用，所以将彩色图转化为灰度图。而对图像进行Gamma校正则是为了调节图像的对比度，降低局部光照不均匀或者阴影的影响。
- 接着采用梯度算子，如Sobel算子等对图像进行卷积求取图像梯度幅值和方向。但在原论文中，Dalal和Triggs测试了一系列的卷积核，只有最简单的$[-1, 0, 1]$和$[-1, 0, 1]^T$有不错的效果。
- 然后将图像划分为若干个互不重叠的Cell，如8×8的像素块，并将Cell内像素按梯度方向划分成9部分，最终统计成直方图。
- 最后将多个Cell组合成更大连通块(Block)，将Block内所有Cell的特征向量串联起来便得到该Block的HoG特征描述子。不同block之间可能相互重叠，这样可以更有效地利用局部邻域信息。

## 拟合与对齐 Fitting and Alignment

> 关于拟合和对齐概念层面更详细的介绍，可以参考UIUC CS 543的[课件](https://courses.engr.illinois.edu/cs543/sp2015/lectures/Lecture%2009%20-%20Fitting%20and%20Registration%20-%20Vision_Spring2015.pdf)。

拟合和对齐是计算机视觉中两项重要的技术。拟合指的是找到一个模型的参数，使其能够最好的适应数据；而对齐则是找到一个变换的参数，使得匹配的点能够最佳对齐。二者的解决方法类似，都需要设计一个描述相似度的损失函数，并且设计一个优化方式来避免局部最优解，同时确保运算速度足够快。

常见的拟合与对齐手段包括：

- 全局优化/参数搜索（Global Optimization / Search for Parameters）：
  - 最小二乘拟合（Least Squares Fit）：通过最小化误差的平方和来找到最佳拟合参数。
  - 鲁棒最小二乘（Robust Least Squares）：针对存在噪声和异常值的数据，通过加权最小二乘法或其他鲁棒技术来提高拟合的准确性。
  - 迭代最近点算法（Iterative Closest Point, ICP）：用于两组点云的对齐，通过反复迭代寻找最近点对，来优化变换参数。
- 假设与检验（Hypothesize and Test）：
  - 广义霍夫变换（Generalized Hough Transform）：通过投票机制在参数空间中寻找最佳参数。
  - 随机抽样一致性（RANSAC）：通过随机抽样和迭代优化找到鲁棒的变换参数。

对于假设和检验方法来说，其具体步骤可分为四步：

- 提出参数（Propose Parameters）：尝试所有可能的参数。每个点对所有一致的参数进行投票。反复采样足够多的点以求解参数。
- 对参数进行评分（Score the Given Parameters）：计算一致点的数量，并可能根据距离进行加权。
- 选择参数（Choose from Among the Set of Parameters）：选择得分最高的参数，可以是全局或局部最大值。
- 参数细化（Possibly Refine Parameters Using Inliers）：使用内点对参数进行进一步优化。

### 霍夫变换

霍夫变换(Hough Transform)则是通过将图像从图像空间变换到参数空间，使得同一个曲线上的点在参数空间内具有相同的参数值。利用参数空间上的累加器统计每个参数值出现的频率，最大频率处即为所求形状的方程参数。哈夫变换的经典应用是从边缘像素中检测直线和圆形等。

**优点**：

- 对离群值具有鲁棒性：每个点单独投票。
- 相对高效（比尝试所有参数集要快得多）。
- 提供多个良好的拟合结果。

**缺点**：

- 对噪声有一定敏感性。
- 需要在噪声容忍度、精度和速度/内存之间进行权衡，难以找到最佳点。
- 不适合处理多个参数，网格大小呈指数级增长。

#### 霍夫直线变换

在图像x−y坐标空间中，经过点(xi,yi)的直线表示为：$y_i=a*x_i+b$。其中，参数a为斜率，b为截矩。

通过点(xi,yi)的直线有无数条，且对应于不同的a和b值。如果将xi和yi视为常数，而将原本的参数a和b看作变量，则原直线表达式上可以表示为：$b=-x_i*a+y_i$。考虑到图像坐标空间中的另一点(xj,yj)，它在参数空间中也有相应的一条直线，表示为：$b=-x_j*a+y_j$。这条直线与点(xi,yi)在参数空间的直线相交于一点(a0,b0)，如图所示：

![霍夫直线变换](https://img-blog.csdn.net/2018081316531669?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3podV9ob25namk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

可见，(a0,b0)就是点(xi,yi)和点(xj,yj)确定的参数。根据这个特性，给定图像坐标空间的一些边缘点，就可以通过Hough变换确定连接这些点的直线方程。

在实际运用中，首先确定(a, b)两个参数可能的范围并定义一个二维数组A，然后依次将每个点(x, y)和a所有取值代入，从而计算出所有可能b取值。接着使用二维数组记录所有(a, b)对出现的次数。最后将其二值化，高出阈值的就是最终得到的所有直线。

#### 霍夫圆变换

霍夫变换同样适用于方程已知的曲线检测，比如圆。其图像坐标空间到参数空间的变换公式如下：$x=a+Rcos(\theta), y=b+Rsin(\theta)$。因此，参数空间可以表示为(a,b,r)，图像坐标空间中的一个圆对应参数空间中的一个点。具体计算时，与前面讨论的方法相同，只是数组累加器为三维A(a,b,r)。 计算过程是让a,b在取值范围内增加，解出满足上式的r值，每计算出一个(a,b,r)值，就对相应的数组元素A(a,b,r)加1.计算结束后，找到的最大的A(a,b,r)所对应的a,b,r就是所求的圆的参数。

### RANSAC

随机抽样一致算法(Random Sample Consensus, RANSAC)采用迭代的方式从一组包含离群的被观测数据中估算出数学模型的参数。它的一般流程是：

- 在数据中随机选择若干个点设定为内点群；
- 计算拟合内点群的模型；
- 把其它刚才没选到的点带入刚才建立的模型中，计算是否属于内点群；
- 记下内点群数量；
- 重复以上步骤；
- 比较哪次计算中内点群数量最多，内点群最多的那次所建的模型就是我们所要求的解。

**优点**：

- 对离群值（非内点）具有鲁棒性。
- 适用于比霍夫变换更多的目标函数参数。
- 优化参数比霍夫变换更容易选择。

**缺点**：

- 随着离群值比例和参数数量的增加，计算时间迅速增长。
- 不适合获取多个拟合结果（尽管可以通过每次拟合后移除内点并重复来解决）。

### 应用——图像融合

图像的对齐和拼接(Image Alignment and Stitching)是模型匹配最重要的应用，它的一般流程是：

- 检测关键点；
- 建立SIFT描述子；
- 使用RANSAC选择匹配子集
- 根据匹配的特征点对计算变换矩阵；
- 在重叠区域混合图像。

**如何使用RANSAC进行SIFT特征匹配**：

简而言之，使用RANSAC进行特征点匹配的过程分为以下几步：

- 从两张图片中已经确定一定匹配的特征点集中随机选取4个点对用于计算变换矩阵；
- 根据该变换矩阵和可接受误差判断外点(Outliners)在两张图中匹配的数量；
- 反复迭代上述两步，选出最优秀的变换矩阵。

关于这一点更详细的介绍，可以查看[博客](https://blog.csdn.net/masibuaa/article/details/9145441)。

## 聚类和分割 Clustering and Segmentation

### 聚类分析

聚类分析(Clustering)是一种无监督学习方法，旨在将数据集中的样本划分为若干组（簇），使得同一组内的样本具有较高的相似度，而不同组间的样本差异较大。

#### Hierarchical Clustering

层次性聚类(Hierarchical Clustering)是一种不需要预先指定簇数量的聚类方法，通过构建层次树来表示数据的聚类结构。具体步骤如下：

- 初始化：每个数据点作为一个单独的簇。
- 合并簇：根据某种距离度量（如最小距离、最大距离、平均距离）合并最相似的两个簇。
- 迭代：重复步骤2，直到所有数据点被合并到一个簇中。

一般来说，层次性聚类分为两种类型：

- 自底向上（Agglomerative）：从个体开始，不断合并簇。
- 自顶向下（Divisive）：从整体开始，不断拆分簇。

#### K-means

K-means是一种常见的聚类算法，其核心思想是将数据点分配到K个簇中，使得每个簇内的数据点与该簇的中心（质心）之间的距离平方和最小。具体步骤如下：

- 初始化：随机选择K个质心。
- 分配数据点：将每个数据点分配到最近的质心所在的簇中。
- 更新质心：重新计算每个簇的质心。
- 迭代：重复步骤2和3，直到质心不再发生变化或达到预设的迭代次数。

**KNN vs K-means**：

值得一提的是，KNN算法往往会和K-means算法混淆。因为二者不管是名字，还是实现步骤都非常相似。但两者有一个最显著的区别，就是它们分属监督学习和无监督学习。这也是分类和聚类最主要的区别。对于监督学习中的KNN来说，它根据实现定义好的标准，根据数据特征将其归类到某一类别中，即：数据有标签；而对于无监督学习中的K-means来说，它是直接根据数据的相似性将其分为指定数量的组，其数据是无标签的。

**Bag of Visual Words**：

Bag of Visual Words（BoVW）是一种将图像表示为视觉词袋的方法，如下图所示。

![BoVW](https://customers.pyimagesearch.com/wp-content/uploads/2015/09/bovw_image_example.jpg)

BoVW常用于图像分类和检索任务，因为它能够将图像转化为固定长度的特征向量，方便后续的分类器训练。一般来说，它的生成步骤如下：

- 特征提取：从图像中提取局部特征（如SIFT、SURF）。
- 词汇生成：通过聚类算法（如K-means）将局部特征聚类为视觉词汇。
- 直方图表示：将每个图像表示为视觉词汇的直方图，即每个词汇在图像中出现的频率。

![BoVW Workflow](https://kr.mathworks.com/help/vision/ug/bagoffeatures_visualwordsoverview.png)

#### 均值漂移

均值漂移(Mean Shift)是一种基于密度的局部最优算法，可用于聚类、图像分割和目标追踪。其核心思想是通过迭代移动数据点到高密度区域的均值中心，最终形成簇。具体步骤如下：

- 初始化：对于每个数据点，初始化一个窗口。
- 计算均值：在窗口内计算所有数据点的均值。
- 移动窗口：将窗口中心移动到计算出的均值位置。
- 迭代：重复步骤2和3，直到窗口中心不再发生显著变化。

相比K-means算法，Mean Shift算法的优势是不需要指定簇的数量K，且能够识别任意形状的簇，而不是像K-means倾向生成球形簇。

### 图像分割

图像分割是一种将图像划分为若干区域，使得每个区域内的像素具有相似特征的技术。传统的图像分割算法大体上可以分为以下几类：

**基于阈值和边缘检测的图像分割**：

其中，最简单也是前面所提到过的两种图像分割方法就是基于阈值和基于边缘检测的手段。前者依靠阈值将图片分成两部分，常见的手段包括：使用直方图可将图片按波谷分成前景和背景两部分、使用阈值将图片二值化然后再通过连通性标记算法完成图片分割。后者则使用图像中的边缘信息来划分区域。边缘检测算法如Sobel、Canny可以检测图像中的边缘，然后通过这些边缘将图像分割成不同的区域。

**基于聚类和区域的图像分割**：

基于聚类的图像分割方法将图像数据看作特征向量，利用聚类算法将图像的像素分为若干簇，每个簇代表一个区域。

基于区域的图像分割方法将相邻相似区域合并，如区域生长、分裂合并等算法。它们根据预先定义的生长规则将像素或者小区域不断组合为更大区域的过程。具体地，区域生长是从一组初始种子点出发，通过预先定义的区域生长规则，将与种子点性质相似的领域像素不断添加到每个种子点上，并且满足区域生长的终止条件时形成最终生长区域的过程。

**基于图论图像分割**：：

基于图论的图像分割方法，它将图像分割问题转化为寻找图的最小割问题，即Graph Cut。对于这种方法，它首先根据图片像素特征构建一个图，其中节点代表像素，边代表像素之间的相似性或连接性。最后定义代价函数，使用最大流最小割算法在图上寻找最小割，将图分割成前景和背景。

#### Watershed算法

分水岭算法(Watershed算法)是一种基于拓扑理论的数学形态学的分割方法。简单来说，Watershed算法其实类似连通性标记算法中的Flood Fill算法。其基本思想是把图像看作是测地学上的拓扑地貌，图像中每一点像素的灰度值表示该点的海拔高度，每一个局部极小值及其影响区域称为集水盆，而集水盆的边界则形成分水岭。分水岭的概念和形成可以通过模拟浸入过程来说明。在每一个局部极小值表面，刺穿一个小孔，然后把整个模型慢慢浸入水中，随着浸入的加深，每一个局部极小值的影响域慢慢向外扩展，在两个集水盆汇合处构筑大坝，即形成分水岭。

## 分类和识别 Categorization and Object Recognition

### 人脸识别

人脸识别是一种重要的计算机视觉任务，涉及从图像中检测并识别个人身份。常见的方法包括主成分分析（PCA）、线性判别分析（LDA）、卷积神经网络（CNN）等。

#### PCA

主成分分析(Principal Component Analysis, PCA)是一种降维技术，旨在通过线性变换将高维数据投影到低维空间，同时尽可能保留数据的方差。在人脸识别中，PCA常用于提取图像的主要特征，以减少计算复杂度并提高识别性能。

PCA的主要思想是将n维特征映射到k维上，这k维是全新的正交特征也被称为主成分，是在原有n维特征的基础上重新构造出来的k维特征。PCA的工作就是从原始的空间中顺序地找一组相互正交的坐标轴，新的坐标轴的选择与数据本身是密切相关的。其中，第一个新坐标轴选择是原始数据中方差最大的方向，第二个新坐标轴选取是与第一个坐标轴正交的平面中使得方差最大的，第三个轴是与第一二个轴正交的平面中方差最大的。依次类推，可以得到n个这样的坐标轴。通过这种方式获得的新的坐标轴，我们发现，大部分方差都包含在前面k个坐标轴中，后面的坐标轴所含的方差几乎为0。于是，我们可以忽略余下的坐标轴，只保留前面k个含有绝大部分方差的坐标轴。事实上，这相当于只保留包含绝大部分方差的维度特征，而忽略包含方差几乎为0的特征维度，实现对数据特征的降维处理。

在实际应用中，PCA算法首先计算原数据的协方差矩阵，然后对其使用特征分解，得到其特征值和相应的特征向量。排序后选择前k个大特征值所对应的特征向量，即可实现对原数据的降维处理。

此外，对于某些数据量较大的矩阵，计算其协方差再进行特征值分解就会比较耗时。因此，可以采用奇异值分解，避免计算显式地计算协方差矩阵。在线性代数中，奇异值分解和特征值分解是两种常用的矩阵分解方法。其中，特征值分解主要用于方阵，它将方阵分解为特征值和特征向量的形式。设A是一个n×n的方阵，如果存在一个非零向量v和一个标量λ满足Av=λv，则λ是A的特征值，v是对应的特征向量。特征值分解的结果是A=VΛV^-1，其中V是特征向量组成的矩阵，Λ是对角矩阵，对角线上的元素是特征值。而奇异值分解适用于任意m×n的矩阵，它将矩阵分解为三个部分，即A=UΣV^T，其中U和V是正交矩阵（U是m×m，V是n×n），Σ是对角矩阵，对角线上的元素是奇异值。

#### LDA

线性判别分析(Linear Discriminant Analysis, LDA)和PCA原理类似，也是一种降维技术。

**和PCA的区别**：

和PCA相比，LDA是一种监督学习方法，旨在找到最大化类别间方差和最小化类别内方差的投影方向。LDA不仅考虑数据的内在结构，还考虑了类别标签，目的是找到区分不同类别的特征。而PCA则是一种无监督学习方法，目标是找到数据的主成分，即数据方差最大的方向，以减少数据的维度并保留尽可能多的信息。PCA不考虑类别信息，只关注数据的内在结构。

#### Eigenface and Fisherface

- Eigenface：是一种基于PCA的面部识别方法。它首先通过PCA将高维的面部图像降维，得到一组特征脸（Eigenfaces），这些特征脸是原始图像的线性组合，可以表示所有训练图像。在识别阶段，新图像被投影到特征脸空间，找到最接近的训练样本。
- Fisherface：是基于LDA的面部识别方法。与Eigenface相比，Fisherface不仅考虑图像的内在结构，还考虑了类别信息。它通过最大化类间散度和最小化类内散度来找到最优的投影方向，生成的Fisherfaces更专注于区分不同的人脸。

### 基于机器学习的分类器

#### KNN

#### SVM

#### 决策树

## 检测和追踪 Detection and Tracking

### 目标检测

不同于目标识别(Object Regconition)，目标检测(Object Detection)并非图片层面。前者只关注一张图片中是否包含某种特定类别物体即可，而后者不仅识别图像中是否存在特定物体，还要确定物体的位置和大小，通常以边界框的形式表示，例如在一张图片中同时检测人、车、猫等。

![时间轴线图](https://img-blog.csdnimg.cn/280feeef699349399f84b3ca40fecb1d.jpeg#pic_center)

整个目标检测技术的发展历史如上图所示。这些方法可按2012年AlexNet的出现前后分成传统方法和深度学习方法。其中，传统方法主要分为基于特征和基于分割两类。前者通过诸如Harr、HoG和SIFT等特征来找到目标对象，后者则通过检测边缘或区域来实现。对于基于特征的目标检测方法来说，它大体上可将步骤按下图划分。

![基于特征的传统方法流程](https://img-blog.csdnimg.cn/c10b2e7fd04c4ef4bc38d36ae431f0ca.jpeg#pic_center)

2012年之后随着算力及数据的提升，大量的深度学习模型涌现。最开始的模型主要采用的是以RCNN为首的two-stage目标检测模型。但随着移动端对目标检测效率要求的提高，16年之后模型开始往以YOLO为首的one-stage模型发展。但前面两种模型都比较依赖anchor的设定，即预先定义的边界框。为减少anchor对模型的影响，18年以后开始兴起了对以CornerNet为首的anchor-free研究。17年底谷歌推出了Transformers模型，随后在19年开始大火并快速地应用于CV领域。在20年时，Facebook AI团队首次将Transformers模型应用于目标检测领域，开启了目标检测新的研究浪潮。

#### VJ and HoG+SVM

2004年Paul Viola和MichaelJones在CVPR上发表了一篇跨时代意义的文章《Robust Real-Time Face Detection》，后人将文章中的人脸检测算法称之为VJ算法。它极为有限的计算资源下第一次实现了人脸的实时检测，速度是同期检测算法的几十甚至上百倍，极大程度地推动了人脸检测应用商业化的进程。

具体来说，VJ算法由三个核心步骤组成，即Haar-like特征和积分图、Adaboost分类器和级联分类器。

#### DPM

(Deformable Part Model, DPM)

#### R-CNN

区域卷积神经网络(Region-CNN, R-CNN)是第一个将深度学习应用到目标检测的算法。它整体上类似基于特征的传统方法，同样是生成提取框，对每个框提取特征、图像分类、非极大值抑制四个步骤进行目标检测。只不过在提取特征这一步，将传统的特征方法(如SIFT、HoG等)换成了深度卷积网络。具体来说，R-CNN首先使用Selective Search方法生成大约2000个大小不同的提取框。接着，使用AlexNet对每一个提取框进行特征提取，并将这些提取到的特征交给SVM分类器判断，得到每个区域中每个物品类别的概率。最后，使用非极大值抑制(Non Maximum Suppression, NMS)方法来剔除冗余和重叠的候选区，最终得到每一个类别得分最高一些区域。

**Region Proposal Algorithm**：

其中，Selective Search是一种候选区域生成方法(Region Proposal Algorithm)。它结合了穷举搜索和图片分割的优势。它首先使用Felzenszwalb and Huttenlocher的[方法](https://cs.brown.edu/people/pfelzens/papers/seg-ijcv.pdf)快速分割方法生成初始小区域，然后使用贪婪算法根据相似性迭代合并这些小区域，从而生成区域层次结构。除了Selective Search之外，常见的区域生成方法还有区域生成网络(Region Proposal Network, RPN)。它也正是后续Fast RCNN针对RCNN的改进。它使用深度神经网络来生成区域。

**Non Maximum Suppression**：

非极大值抑制(Non Maximum Suppression, NMS)是一种去除非极大值的算法，在计算机视觉任务中得到了广泛的应用，例如边缘检测、人脸检测、目标检测。尽管它在不同应用中的具体实现不太一样，它的思想都是搜素局部最大值。

在目标检测中，NMS算法是用来消除重叠候选区，保留最优提取框的。一般来说，它的计算流程如下：

- 假设有N个框，每个框被分类器计算得到的分数为Si, 1<=i<=N。
- 建造一个存放待处理候选框的集合H，初始化为包含全部N个框；另建造一个存放最优框的集合M，初始化为空集。
- 将所有集合H中的框进行排序，选出分数最高的框m，并将其从集合H移到集合M。
- 遍历集合H中的框，分别与框m计算交并比(Interection-over-union，IoU)，如果高于某个阈值（一般为0~0.5），则认为此框与m重叠，将此框从集合H中去除。
- 回到第1步进行迭代，直到集合H为空，得到最优框集合M。

#### YOLO

YOLO(You Only Look Once)是由Joseph Redmon等人在2015年提出的一种快速、高效的目标检测算法。相比于R-CNN这类二阶段算法，YOLO不需要像DPM那样使用滑动窗口依次判定或是像R-CNN那样使用Selective Search生成大量候选区，而是直接对整张图像进行目标检测和分类，并输出每个目标框的位置和类别概率。事实上，YOLO并没有去除候选区，只是大大减少了候选区的数量。在[YOLO v1论文](https://arxiv.org/pdf/1506.02640)中，它将图片分成7×7的网格，每个网格允许生成2个候选区，即共98个候选区。

![YOLO v1](https://img-blog.csdnimg.cn/direct/e88d62fe328f4e95bcfd0f35e24e540c.png)

### 目标追踪

目标追踪(Object Tracking)是指在连续的视频帧中跟踪特定物体的过程。不同于目标检测，目标追踪可以在不识别出场景中物品的前提下，仅依靠动作特点识别。关于二者的区别，可以参考Quora的讨论[What is the difference between object detection and object tracking?](https://www.quora.com/What-is-the-difference-between-object-detection-and-object-tracking)。

一般来说，目标追踪的方法可分成生成式目标追踪算法(Generative Object Trackinng)和鉴别式目标追踪算法(Discriminative Object Tracking)。前者包括光流法、MeanShift算法等，它们首先建立目标模型或者提取目标特征，在后续帧中进行相似特征搜索，逐步迭代实现目标定位。而后者通过对比目标模型和背景信息的差异，将目标模型提取出来，从而得到当前帧中的目标位置。

#### Lucas-Kanade光流法

**光流法基本假设**：

光流法实际是通过检测视频帧像素点强度随时间的变化进而推断出物体移动速度及方向的方法。它的实现依赖两个最基本假设，分别是：

- 亮度恒定：目标像素的强度在相邻帧发生的变化足够小，近似一致。这意味着如果一个像素在第一帧的位置是(x, y)，在第二帧的位置是I(x+dy, y+dy, t+dt)，那么它在两帧中的亮度应该相同，即：I(x, y, t)=I(x+dy, y+dy, t+dt)。
- 时间规律：相邻帧的时间间隔足够短。光流假设像素的运动是连续的，即相邻帧之间的光流变化应该是平滑的。

**光流法基本原理**：

根据上述假设，可以将亮度恒定的公式进行泰勒展开，得到$I(x, y, t)=I(x, y, t)+\frac{\partial I}{\partial x}\frac{\partial x}{\partial t}+\frac{\partial I}{\partial y}\frac{\partial y}{\partial t}+\frac{\partial I}{\partial t}+O(\Delta t)$。忽略最后的佩亚诺余项，得到$\frac{\partial I}{\partial x}\frac{\partial x}{\partial t}+\frac{\partial I}{\partial y}\frac{\partial y}{\partial t}+\frac{\partial I}{\partial t}=0$，这就是光流法的约束方程。

将其记为$I_xu+I_yv+I_t=0$，u和v代表两个方向(x方向和y方向)的移动速度，而$I_x, I_y, I_t$则代表了亮度在三个轴上的偏导（也就是梯度）。选择图像中某个特征点，使用上述基本约束方程，求解出其中的u和v，这就是光流法实现目标追踪的本质。其中，$I_x, I_y$可以通过指定位置像素强度之差得出，而$I_t$则可用通过指定位置前后两帧像素强度之差得出。但这仍不足以通过一个方程求出两个变量u和v，可见想要通过光流法实现目标追踪还需引入额外的假设。

**Lucas-Kanade额外假设与计算方法**：

Lucas-Kanade光流法在两个基本假设的基础上，额外添加了一个空间一致的假设，即：相邻像素拥有相似的运动。这意味着如果一个像素移动了，那么它周围的像素也倾向于以相似的速度和方向移动。因此，LK算法可以选择一个大小为m×n的窗口观察光流变化，由此得到m×n个约束等式，即：

![LK约束不等式](../img/computer_vision_LK_optical_flow.png)

因此，整个问题就被转化为，找到一组(u,v)，使其满足$x=\mathop{argmin}\limits_{x}||Ax-b||$。

**孔径问题**：

为了避免$I_x, I_y$其中一项为0，导致u和v中某项无法求解。在追光流的时候，选点通常会选目标的角点。这种因选点不合理，而产生的x或y方向梯度为0的问题也被称为孔径问题。

#### 卡尔曼滤波

卡尔曼滤波(Kalman Filter)是一种能够对目标的位置进行有效预测的算法。它建立状态方程，将观测数据进行状态输入，对方程参数进行优化。通过对前n帧数据的输入，可以有效地预测第n帧中目标的位置，Kalman 估计也叫最优估计。因此，在目标跟踪过程中，当目标出现遮挡或者消失时，加入Kalman滤波可以有效地解决这种问题。缺点是是Kalman滤波只适合于线性系统，适用范围小。

针对Kalman滤波适用范围小这一问题，人们提出了粒子滤波的方法。粒子滤波(Particle Filter)的思想源于蒙特卡洛思想，它利用特征点表示概率模型。这种表示方法可以在非线性空间上进行计算，其思想是从后验概率中选取特征表达其分布。最近，人们也提出了改进平方根容积卡尔曼滤波的方法来减小误差，从而实现精准跟踪。

#### 核方法

#### 相关滤波方法

以上介绍的三种方法就是目标追踪最经典的方法

## 其他

### 连通域分析

连通域分析(Connectivity Analysis)是根据指定的起始和终止结点，分析两点之间是否连通；或根据指定多个点，分析多个点之间是否互通。在图像处理领域或计算机视觉领域，连通性分析其实就是寻找具有相同灰度值的相邻像素组成的区域。它可根据连通规则分为4邻域连通和8邻域连通，如下图所示。

![4-connectivity vs 8-connectivity](../img/computer_vision_connectivity.jpg)

**Two Pass and Flood Fill**：

常见的连通域标记算法包括[Two Pass算法](https://zh.wikipedia.org/zh-cn/%E8%BF%9E%E9%80%9A%E5%88%86%E9%87%8F%E6%A0%87%E8%AE%B0)和[Flood Fill算法](https://zh.wikipedia.org/wiki/Flood_fill)。其中，Two Pass算法正如其名，需要扫描两次图片来完成标记。以使用它做8连通分析为例，它接收一个二值图片作为输入，然后从左至右依次遍历每一个像素。当它遇到灰度值为0的像素时，不做处理；当它遇到灰度值为1的像素时，分析其已被扫描的8邻域像素点，即左边、左上、上和右上这四个方向的像素值：

- 如果这四个方向的值都是0，那么该位置就创建一个新的标号（在原标号上加1）；
- 如果这四个方向的非0值（即标号）都一样，那么该位置标号就是其领域的非0标号；
- 如果这四个方向的非0值有两个不同的标号，那么该位置标号就选其中之一，并记录这两个不同的标号（因为这两个标号是连通的，故视为等同的标号）；

完成第一次扫描后，会得到初步标好号的图以及哪些标号是相同的信息。此时，进行第二次扫描，根据连通的标号信息，合并这些相同的标号得到最终结果。

至于Flood Fill算法，它其实就是依次遍历每一个像素，对灰度值为1的像素进行深度优先搜索或广度优先搜索，然后将其标号，并使用额外的一个数组标记这些已被深度优先搜索或广度优先搜索访问的位置。当下次再遍历时，直接跳过即可。依靠这种方法，最终也可以得到一张被标记好连通域的图片。

**Library Support**：

常见的图像处理工具都提供了连通域标记函数，比如python-opencv提供的cv2.connectedComponents函数、scikit-image提供的skimage.measure.label函数、scipy提供的scipy.ndimage.measurements.label等。

### 阈值处理

## 参考

- [UIUC cs543 Computer Vision](https://courses.engr.illinois.edu/cs543/sp2015/)
- [Princeton COS 429 - Computer Vision](https://www.cs.princeton.edu/courses/archive/fall17/cos429/cos429.html)
- [浙江大学计算机视觉](https://qsctech.github.io/zju-icicles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/)
