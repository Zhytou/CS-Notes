# 计算机视觉基础

- [计算机视觉基础](#计算机视觉基础)
  - [特征检测与描述 Detector and Descriptor](#特征检测与描述-detector-and-descriptor)
    - [边缘检测](#边缘检测)
      - [边缘检测算子](#边缘检测算子)
      - [滤波器基础](#滤波器基础)
      - [Canny算法](#canny算法)
    - [角点检测](#角点检测)
      - [Harris](#harris)
      - [Harris-Laplace](#harris-laplace)
    - [斑点检测](#斑点检测)
      - [LoG](#log)
      - [DoG](#dog)
    - [特征描述](#特征描述)
      - [SIFT](#sift)
      - [SURF](#surf)
      - [HoG](#hog)
  - [拟合与对齐 Fitting and Alignment](#拟合与对齐-fitting-and-alignment)
    - [霍夫变换](#霍夫变换)
      - [霍夫直线变换](#霍夫直线变换)
      - [霍夫圆变换](#霍夫圆变换)
    - [RANSAC](#ransac)
    - [应用——图像融合](#应用图像融合)
  - [聚类和分割 Clustering and Segmentation](#聚类和分割-clustering-and-segmentation)
    - [聚类分析](#聚类分析)
      - [Hierarchical Clustering](#hierarchical-clustering)
      - [K-means](#k-means)
      - [Mean Shift](#mean-shift)
    - [图像分割](#图像分割)
      - [居于聚类分析的分割](#居于聚类分析的分割)
      - [超像素算法](#超像素算法)
  - [分类和识别 Categorization and Object Recognition](#分类和识别-categorization-and-object-recognition)
    - [人脸识别](#人脸识别)
      - [PCA](#pca)
      - [LDA](#lda)
      - [Eigenface and Fisherface](#eigenface-and-fisherface)
    - [基于机器学习的分类器](#基于机器学习的分类器)
      - [KNN](#knn)
      - [SVM](#svm)
      - [决策树](#决策树)
  - [检测和追踪 Detection and Tracking](#检测和追踪-detection-and-tracking)
    - [目标检测](#目标检测)
      - [VJ and HoG+SVM](#vj-and-hogsvm)
      - [DPM](#dpm)
      - [R-CNN](#r-cnn)
      - [YOLO and SSD](#yolo-and-ssd)
    - [目标追踪](#目标追踪)
      - [光流法](#光流法)
      - [卡尔曼滤波器](#卡尔曼滤波器)
  - [其他](#其他)
    - [连通域分析](#连通域分析)
    - [阈值处理](#阈值处理)
  - [参考](#参考)

## 特征检测与描述 Detector and Descriptor

在计算机视觉领域中，常见的[特征](https://en.wikipedia.org/wiki/Feature_(computer_vision))可分为三类，分别是：

- Edge
- Corner/Interest Points/Key Points
- Blob/Region Of Interest Points

### 边缘检测

在图像中，一个物体的边缘或者轮廓往往会发生灰度值突变。因此，可以采用计算其灰度值导数（即相邻像素灰度差分）的方式检测边缘。一个最简单的边缘检测步骤如下：

- 将彩色图像转为灰度图像；
- 使用边缘检测算子计算灰度值变换率和变换方向，即求导得出梯度（方向和大小）；
- 使用单一阈值将梯度阈值进行二值化，得到二值边缘图。

#### 边缘检测算子

边缘检测算子也就是在检测边缘中用于计算灰度值梯度的运算符。它可依据求导次数分为一阶导数算子和二阶导数算子。当计算图像边缘的导数时，一阶导数通常产生较粗的边缘，即边缘处导数一直非零；而二阶导数则产生两个有间距的双边缘（由零分开，单像素宽）。关于二者区别，具体如下图所示。

![一阶导数和二阶导数的区别](../img/computer_vision_differential.png)

常见的边缘检测算子包括：

- **Roberts算子**：利用对角相邻像素点进行卷积计算梯度。
- **Sobel算子**：该算子包含两组3x3的矩阵，分别为横向及纵向。将之与图像作平面卷积，即按所示方程式计算：
  $$
  G_x*A = [[1, 0, -1], [2, 0, -2], [1, 0, -1]]*A = [f(x+1, y-1)+2*f(x+1, y)+f(x+1, y+1)]-[f(x-1, y-1)+2*f(x-1, y)+f(x-1, y+1)]
  G_y*A = [[1, 2, 1], [0, 0, 0], [-1, -2, -1]]*A = [f(x-1, y+1)+2*f(x, y+1)+f(x+1, y+1)]-[f(x-1, y-1)+2*f(x, y-1)+f(x+1, y-11)]
  $$
- **Prewitt算子**：原理与Sobel类似，但使用不同的卷积核。

#### 滤波器基础

事实上，这些用于边缘检测的算子正是数字图像处理中的锐化滤波器。它基于卷积差分，能够增强边界和突出细节。而与之对应的正是基于卷积求和的平滑滤波器，二则一起组成了空间域滤波器。其中，平滑滤波器可按计算方法分为平滑线性滤波器和统计排序（非线性）滤波器，包括：

- **均值滤波器**是最简单的线性滤波器，它通过计算像素邻域内的像素值平均值来替换中心像素的值。这有助于消除噪声，但可能导致边缘模糊。
- **加权线性滤波器**使用不同权重的邻域像素值进行滤波，权重通常随着距离中心像素的增加而减小。
- **高斯滤波器**是加权线性滤波器的一个例子，其权重由高斯函数决定，对中心像素赋予最大权重，对远离中心的像素赋予较小权重，这在平滑图像的同时能较好地保持边缘。
- **中值滤波器**是一种非线性滤波器，它将中心像素替换为其邻域像素排序后的中值。这种方法对椒盐噪声有很好的去除效果，同时能较好地保护边缘。

#### Canny算法

尽管使用边缘检测算子得到灰度值梯度之后，可以直接用其梯度幅度二值化得到边缘二值图像，但是这样做有两个缺点：

- 没有充分利用梯度的方向信息；
- 仅简单使用单阈值进行处理。

因此，Canny边缘检测算法被提出了。它针对上面两个缺点提出了改进，分别是：

- 基于边缘梯度方向的非极大值抑制；
- 双阈值的滞后阈值处理。

具体来说，Canny算法的步骤为：

- 噪声抑制：在梯度计算之前，Canny算法先进行高斯滤波以平滑图像，有效地减少了噪声对边缘检测的影响。
- 非极大值抑制：Canny算法在梯度幅值图上进行非极大值抑制，确保边缘的精确定位。简单来说，它会去寻找像素点局部最值。在每一点上，领域中心与沿着其对应的梯度方向的两个像素相比，若中心像素为最大值，则保留；否则中心置0。这样可以抑制非极大值，保留局部梯度最大的点，以细化边缘。
- 双阈值检测：Canny算法使用双阈值检测来区分强边缘和弱边缘。
  - 如果某一像素位置的幅值超过高阈值，该像素为强边缘像素，将会被保留。
  - 如果某一像素位置的幅值小于低阈值，该像素被排除。
  - 如果某一像素位置的幅值在两个阈值之间，该像素为弱边缘像素，按和强边缘的连通性选择是否保留。
- 边缘连接：Canny算法根据弱边缘和强边缘的连通性选择是否保留弱边缘。

### 角点检测

在计算机视觉领域中，关键点，也被称为兴趣点或角点，是指图像中独特且重要的点或特征。它们的特点是，在任意方向上的一个微小变化造成其灰度的剧烈变化。一般来说，角点通常位于两条或多条边缘的交汇处。

#### Harris

**基本原理**：

Harris角点检测的原理是，使用指定大小的窗口中在图片各个方向上平移，观察窗口内容的相似程度。其判定方法和示例图如下：

- 当沿任意方向窗口内部图像均基本无变化时，判定为Flat；
- 当且仅当沿某方向窗口内部图像基本无变化时，判定为edge；
- 当沿任意方向窗口内部图像均发生变化时，判定为Corner。

![flat、edge、corner图例](https://ooo.0o0.ooo/2017/06/28/5953a445031a0.jpg)

**数学推导**：

当站在数学角度进行严格推导时，该算法使用自相关函数去描述平移后窗口w(x, y)内图片I(x, y)的相似程度，其公式如下：$E(u, v)=\Sigma_x\Sigma_yw(x, y) [I(x+u, y+v)-I(x, y)]^2$。

当平移量u和v很小时，可以对E(u, v)进行泰勒展开，其公式如下：$E(u, v)=[I(x, y)+uI_x+vI_y-I(x, y)]^2=u^2I_x^2+v^2I_y^2+2uvI_xI_y$。

对于上述自相关函数E(u, v)，可以进一步对其使用特征分解得到特征值$\lambda_1, \lambda_2$，而使用该特征值进行判定的方法如下图。

![特征值判断方法](https://ooo.0o0.ooo/2017/06/28/5953b3774c2f2.png)

然而在实际运用中，无需具体计算特征值，而使用一个量化指标R去判断。该指标的计算方法如下：$R=det(M)-trace(M)^2$。其中det(M)和trace(M)分别为矩阵M的行列式和迹。

- 当R大于零，且其绝对值很大时，为角点；
- 当R小于零，且其绝对值也很大时，为边。

**算法特点**：

- 旋转、平移不变性；
- 图像有偏置时极值点不变；
- 无尺度不变性。 ——> Solution: Harris-Laplace / SIFT

关于Harris角点检测的详细介绍，可以参考博客[图像特征之Harris角点检测](https://senitco.github.io/2017/06/18/image-feature-harris/)。

#### Harris-Laplace

### 斑点检测

斑点是图像中具有一致性特征的区域，这些特征可能是亮度、颜色或者纹理等。一般来说，斑点通常是图像中的局部极值点，即在某个邻域内有显著不同于周围像素的点。斑点检测的目的是找出这些极值点及其所在的区域。

#### LoG

高斯拉普拉斯(Laplacian of Gaussian, LoG)算子是最常见的斑点检测算法。它首先将图片与高斯核进行卷积以平滑影像，然后应用拉普拉斯算子，斑点在拉普拉斯响应达到显著值的点处被检测出来。

#### DoG

高斯差(Differential of Guassian)算子是一种近似LoG的斑点检测算法。它通过计算两个不同标准差的高斯平滑图像的差值来近似LoG的效果。

### 特征描述

> ![What is the difference between feature detectors and feature descriptors?](https://dsp.stackexchange.com/questions/24346/what-is-the-difference-between-feature-detectors-and-feature-descriptors)

#### SIFT

> 关于SIFT算法的详细介绍，可以参考博客[你对SIFT算法了解多少—原理详解与演示](https://blog.csdn.net/DIPDWC/article/details/117605628)。

尺度不变特征变换(Scale Invariant Feature Transform, SIFT)是计算机视觉中一种检测、描述和匹配图像局部特征点的方法，通过在不同的尺度空间中检测极值点或特征点 (Conrner Point, Interest Point) ，提取出其位置、尺度和旋转不变量，并生成特征描述子，最后用于图像的特征点匹配。也就是说，和Harris、FAST这类特征点检测算法相比，SIFT算法不仅能够检测还能够描述进而用于后续的匹配操作，比如图像融合等。

**尺度空间**：

尺度空间(Scale Space)理论描述了图像的模糊程度和人感知其大小的关系。近距离看一个物体和远距离看一个物体，模糊程度是不一样的；从近到远，图像越来越模糊的过程，也是图像的尺度越来越大的过程。一般来说，使用图片金字塔来模拟尺度空间。

**计算流程**：

- 为了提取到不受尺度变换影响的特征，SIFT需要首先生成图片金字塔。具体来说，它采用DoG算子获取高斯差分金字塔。
- 接着，在该金字塔内找到极值点。由于DoG算子是LoG算子的近似，且一般用于Blob检测。因此，这些极值点实际就是图像中较暗或者较亮的斑点。
- 然后，筛选上述选出的极值点，剔除低对比度和不稳定的边缘响应点。
- 接着，确定这些关键点的具体位置，并且计算其在邻域窗口内的梯度幅值和方向。
- 最后，依据关键点位置(x,y)和尺度σ在高斯金字塔上确定采样区域，计算该区域内梯度幅值和方向，并统计具有高度旋转不变性的8邻域梯度直方图。组合8邻域的直方图(4x4矩阵),共计算128维SIFT特征向量

#### SURF

#### HoG

方向梯度直方图(Histogram of Oriented Gradient, HoG)在计算机视觉邻域中一种常用于目标检测(Object Detection)的特征描述器。Navneet Dalal和Bill Triggs于2005年在CVPR发表了使用HoG结合SVM分类器进行行人检测的论文。目前，HoG结合SVM分类器已经被广泛应用于目标检测中。具体来说，HoG首先计算每个像素点的梯度幅值和方向，然后在细分的小区域(Cell)内统计梯度方向直方图，最终构成特征向量。

**计算流程**：

- 首先进行图像预处理，包括灰度化和伽马矫正。因为HoG提取的是纹理特征，颜色信息不起作用，所以将彩色图转化为灰度图。而对图像进行Gamma校正则是为了调节图像的对比度，降低局部光照不均匀或者阴影的影响。
- 接着采用梯度算子，如Sobel算子等对图像进行卷积求取图像梯度幅值和方向。但在原论文中，Dalal和Triggs测试了一系列的卷积核，只有最简单的$[-1, 0, 1]$和$[-1, 0, 1]^T$有不错的效果。
- 然后将图像划分为若干个互不重叠的Cell，如8×8的像素块，并将Cell内像素按梯度方向划分成9部分，最终统计成直方图。
- 最后将多个Cell组合成更大连通块(Block)，将Block内所有Cell的特征向量串联起来便得到该Block的HoG特征描述子。不同block之间可能相互重叠，这样可以更有效地利用局部邻域信息。

## 拟合与对齐 Fitting and Alignment

> 关于拟合和对齐概念层面更详细的介绍，可以参考UIUC CS 543的[课件](https://courses.engr.illinois.edu/cs543/sp2015/lectures/Lecture%2009%20-%20Fitting%20and%20Registration%20-%20Vision_Spring2015.pdf)。

拟合和对齐是计算机视觉中两项重要的技术。拟合指的是找到一个模型的参数，使其能够最好的适应数据；而对齐则是找到一个变换的参数，使得匹配的点能够最佳对齐。二者的解决方法类似，都需要设计一个描述相似度的损失函数，并且设计一个优化方式来避免局部最优解，同时确保运算速度足够快。

常见的拟合与对齐手段包括：

- 全局优化/参数搜索（Global Optimization / Search for Parameters）：
  - 最小二乘拟合（Least Squares Fit）：通过最小化误差的平方和来找到最佳拟合参数。
  - 鲁棒最小二乘（Robust Least Squares）：针对存在噪声和异常值的数据，通过加权最小二乘法或其他鲁棒技术来提高拟合的准确性。
  - 迭代最近点算法（Iterative Closest Point, ICP）：用于两组点云的对齐，通过反复迭代寻找最近点对，来优化变换参数。
- 假设与检验（Hypothesize and Test）：
  - 广义霍夫变换（Generalized Hough Transform）：通过投票机制在参数空间中寻找最佳参数。
  - 随机抽样一致性（RANSAC）：通过随机抽样和迭代优化找到鲁棒的变换参数。

对于假设和检验方法来说，其具体步骤可分为四步：

- 提出参数（Propose Parameters）：尝试所有可能的参数。每个点对所有一致的参数进行投票。反复采样足够多的点以求解参数。
- 对参数进行评分（Score the Given Parameters）：计算一致点的数量，并可能根据距离进行加权。
- 选择参数（Choose from Among the Set of Parameters）：选择得分最高的参数，可以是全局或局部最大值。
- 参数细化（Possibly Refine Parameters Using Inliers）：使用内点对参数进行进一步优化。

### 霍夫变换

霍夫变换(Hough Transform)则是通过将图像从图像空间变换到参数空间，使得同一个曲线上的点在参数空间内具有相同的参数值。利用参数空间上的累加器统计每个参数值出现的频率，最大频率处即为所求形状的方程参数。哈夫变换的经典应用是从边缘像素中检测直线和圆形等。

**优点**：

- 对离群值具有鲁棒性：每个点单独投票。
- 相对高效（比尝试所有参数集要快得多）。
- 提供多个良好的拟合结果。

**缺点**：

- 对噪声有一定敏感性。
- 需要在噪声容忍度、精度和速度/内存之间进行权衡，难以找到最佳点。
- 不适合处理多个参数，网格大小呈指数级增长。

#### 霍夫直线变换

在图像x−y坐标空间中，经过点(xi,yi)的直线表示为：$y_i=a*x_i+b$。其中，参数a为斜率，b为截矩。

通过点(xi,yi)的直线有无数条，且对应于不同的a和b值。如果将xi和yi视为常数，而将原本的参数a和b看作变量，则原直线表达式上可以表示为：$b=-x_i*a+y_i$。考虑到图像坐标空间中的另一点(xj,yj)，它在参数空间中也有相应的一条直线，表示为：$b=-x_j*a+y_j$。这条直线与点(xi,yi)在参数空间的直线相交于一点(a0,b0)，如图所示：

![霍夫直线变换](https://img-blog.csdn.net/2018081316531669?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3podV9ob25namk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

可见，(a0,b0)就是点(xi,yi)和点(xj,yj)确定的参数。根据这个特性，给定图像坐标空间的一些边缘点，就可以通过Hough变换确定连接这些点的直线方程。

在实际运用中，首先确定(a, b)两个参数可能的范围并定义一个二维数组A，然后依次将每个点(x, y)和a所有取值代入，从而计算出所有可能b取值。接着使用二维数组记录所有(a, b)对出现的次数。最后将其二值化，高出阈值的就是最终得到的所有直线。

#### 霍夫圆变换

霍夫变换同样适用于方程已知的曲线检测，比如圆。其图像坐标空间到参数空间的变换公式如下：$x=a+Rcos(\theta), y=b+Rsin(\theta)$。因此，参数空间可以表示为(a,b,r)，图像坐标空间中的一个圆对应参数空间中的一个点。具体计算时，与前面讨论的方法相同，只是数组累加器为三维A(a,b,r)。 计算过程是让a,b在取值范围内增加，解出满足上式的r值，每计算出一个(a,b,r)值，就对相应的数组元素A(a,b,r)加1.计算结束后，找到的最大的A(a,b,r)所对应的a,b,r就是所求的圆的参数。

### RANSAC

随机抽样一致算法(Random Sample Consensus, RANSAC)采用迭代的方式从一组包含离群的被观测数据中估算出数学模型的参数。它的一般流程是：

- 在数据中随机选择若干个点设定为内点群；
- 计算拟合内点群的模型；
- 把其它刚才没选到的点带入刚才建立的模型中，计算是否属于内点群；
- 记下内点群数量；
- 重复以上步骤；
- 比较哪次计算中内点群数量最多，内点群最多的那次所建的模型就是我们所要求的解。

**优点**：

- 对离群值（非内点）具有鲁棒性。
- 适用于比霍夫变换更多的目标函数参数。
- 优化参数比霍夫变换更容易选择。

**缺点**：

- 随着离群值比例和参数数量的增加，计算时间迅速增长。
- 不适合获取多个拟合结果（尽管可以通过每次拟合后移除内点并重复来解决）。

### 应用——图像融合

图像的对齐和拼接(Image Alignment and Stitching)是模型匹配最重要的应用，它的一般流程是：

- 检测关键点；
- 建立SIFT描述子；
- 使用RANSAC选择匹配子集
- 根据匹配的特征点对计算变换矩阵；
- 在重叠区域混合图像。

**如何使用RANSAC进行SIFT特征匹配**：

简而言之，使用RANSAC进行特征点匹配的过程分为以下几步：

- 从两张图片中已经确定一定匹配的特征点集中随机选取4个点对用于计算变换矩阵；
- 根据该变换矩阵和可接受误差判断外点(Outliners)在两张图中匹配的数量；
- 反复迭代上述两步，选出最优秀的变换矩阵。

关于这一点更详细的介绍，可以查看[博客](https://blog.csdn.net/masibuaa/article/details/9145441)。

## 聚类和分割 Clustering and Segmentation

### 聚类分析

聚类分析(Clustering)是一种无监督学习方法，旨在将数据集中的样本划分为若干组（簇），使得同一组内的样本具有较高的相似度，而不同组间的样本差异较大。

#### Hierarchical Clustering

层次性聚类(Hierarchical Clustering)是一种不需要预先指定簇数量的聚类方法，通过构建层次树来表示数据的聚类结构。具体步骤如下：

- 初始化：每个数据点作为一个单独的簇。
- 合并簇：根据某种距离度量（如最小距离、最大距离、平均距离）合并最相似的两个簇。
- 迭代：重复步骤2，直到所有数据点被合并到一个簇中。

一般来说，层次性聚类分为两种类型：

- 自底向上（Agglomerative）：从个体开始，不断合并簇。
- 自顶向下（Divisive）：从整体开始，不断拆分簇。

#### K-means

K-means是一种常见的聚类算法，其核心思想是将数据点分配到K个簇中，使得每个簇内的数据点与该簇的中心（质心）之间的距离平方和最小。具体步骤如下：

- 初始化：随机选择K个质心。
- 分配数据点：将每个数据点分配到最近的质心所在的簇中。
- 更新质心：重新计算每个簇的质心。
- 迭代：重复步骤2和3，直到质心不再发生变化或达到预设的迭代次数。

**KNN vs K-means**：

值得一提的是，KNN算法往往会和K-means算法混淆。因为二者不管是名字，还是实现步骤都非常相似。但两者有一个最显著的区别，就是它们分属监督学习和无监督学习。这也是分类和聚类最主要的区别。对于监督学习中的KNN来说，它根据实现定义好的标准，根据数据特征将其归类到某一类别中，即：数据有标签；而对于无监督学习中的K-means来说，它是直接根据数据的相似性将其分为指定数量的组，其数据是无标签的。

**Bag of Visual Words**：

Bag of Visual Words（BoVW）是一种将图像表示为视觉词袋的方法，如下图所示。

![BoVW](https://customers.pyimagesearch.com/wp-content/uploads/2015/09/bovw_image_example.jpg)

BoVW常用于图像分类和检索任务，因为它能够将图像转化为固定长度的特征向量，方便后续的分类器训练。一般来说，它的生成步骤如下：

- 特征提取：从图像中提取局部特征（如SIFT、SURF）。
- 词汇生成：通过聚类算法（如K-means）将局部特征聚类为视觉词汇。
- 直方图表示：将每个图像表示为视觉词汇的直方图，即每个词汇在图像中出现的频率。

![BoVW Workflow](https://kr.mathworks.com/help/vision/ug/bagoffeatures_visualwordsoverview.png)

#### Mean Shift

Mean Shift是一种基于密度的聚类算法，其核心思想是通过迭代移动数据点到高密度区域的均值中心，最终形成簇。具体步骤如下：

- 初始化：对于每个数据点，初始化一个窗口。
- 计算均值：在窗口内计算所有数据点的均值。
- 移动窗口：将窗口中心移动到计算出的均值位置。
- 迭代：重复步骤2和3，直到窗口中心不再发生显著变化。

相比K-means算法，Mean Shift算法的优势是不需要指定簇的数量K，且能够识别任意形状的簇，而不是像K-means倾向生成球形簇。

### 图像分割

图像分割是一种将图像划分为若干区域，使得每个区域内的像素具有相似特征的技术。最简单，也是前面所提到过的两种图像分割方法就是基于阈值和基于边缘检测的手段。其中，前者使用直方图可将图片按波谷分成前景和背景两部分。后者则使用图像中的边缘信息来划分区域。边缘检测算法如Sobel、Canny可以检测图像中的边缘，然后通过这些边缘将图像分割成不同的区域。

#### 居于聚类分析的分割

基于聚类分析的图像分割方法利用聚类算法将图像的像素分为若干簇，每个簇代表一个区域。常见的算法包括K-means、Mean Shift等。

#### 超像素算法

## 分类和识别 Categorization and Object Recognition

### 人脸识别

人脸识别是一种重要的计算机视觉任务，涉及从图像中检测并识别个人身份。常见的方法包括主成分分析（PCA）、线性判别分析（LDA）、卷积神经网络（CNN）等。

#### PCA

主成分分析(Principal Component Analysis, PCA)是一种降维技术，旨在通过线性变换将高维数据投影到低维空间，同时尽可能保留数据的方差。在人脸识别中，PCA常用于提取图像的主要特征，以减少计算复杂度并提高识别性能。

PCA的主要思想是将n维特征映射到k维上，这k维是全新的正交特征也被称为主成分，是在原有n维特征的基础上重新构造出来的k维特征。PCA的工作就是从原始的空间中顺序地找一组相互正交的坐标轴，新的坐标轴的选择与数据本身是密切相关的。其中，第一个新坐标轴选择是原始数据中方差最大的方向，第二个新坐标轴选取是与第一个坐标轴正交的平面中使得方差最大的，第三个轴是与第一二个轴正交的平面中方差最大的。依次类推，可以得到n个这样的坐标轴。通过这种方式获得的新的坐标轴，我们发现，大部分方差都包含在前面k个坐标轴中，后面的坐标轴所含的方差几乎为0。于是，我们可以忽略余下的坐标轴，只保留前面k个含有绝大部分方差的坐标轴。事实上，这相当于只保留包含绝大部分方差的维度特征，而忽略包含方差几乎为0的特征维度，实现对数据特征的降维处理。

在实际应用中，PCA算法首先计算原数据的协方差矩阵，然后对其使用特征分解，得到其特征值和相应的特征向量。排序后选择前k个大特征值所对应的特征向量，即可实现对原数据的降维处理。

此外，对于某些数据量较大的矩阵，计算其协方差再进行特征值分解就会比较耗时。因此，可以采用奇异值分解，避免计算显式地计算协方差矩阵。在线性代数中，奇异值分解和特征值分解是两种常用的矩阵分解方法。其中，特征值分解主要用于方阵，它将方阵分解为特征值和特征向量的形式。设A是一个n×n的方阵，如果存在一个非零向量v和一个标量λ满足Av=λv，则λ是A的特征值，v是对应的特征向量。特征值分解的结果是A=VΛV^-1，其中V是特征向量组成的矩阵，Λ是对角矩阵，对角线上的元素是特征值。而奇异值分解适用于任意m×n的矩阵，它将矩阵分解为三个部分，即A=UΣV^T，其中U和V是正交矩阵（U是m×m，V是n×n），Σ是对角矩阵，对角线上的元素是奇异值。

#### LDA

线性判别分析(Linear Discriminant Analysis, LDA)和PCA原理类似，也是一种降维技术。

**和PCA的区别**：

和PCA相比，LDA是一种监督学习方法，旨在找到最大化类别间方差和最小化类别内方差的投影方向。LDA不仅考虑数据的内在结构，还考虑了类别标签，目的是找到区分不同类别的特征。而PCA则是一种无监督学习方法，目标是找到数据的主成分，即数据方差最大的方向，以减少数据的维度并保留尽可能多的信息。PCA不考虑类别信息，只关注数据的内在结构。

#### Eigenface and Fisherface

- Eigenface：是一种基于PCA的面部识别方法。它首先通过PCA将高维的面部图像降维，得到一组特征脸（Eigenfaces），这些特征脸是原始图像的线性组合，可以表示所有训练图像。在识别阶段，新图像被投影到特征脸空间，找到最接近的训练样本。
- Fisherface：是基于LDA的面部识别方法。与Eigenface相比，Fisherface不仅考虑图像的内在结构，还考虑了类别信息。它通过最大化类间散度和最小化类内散度来找到最优的投影方向，生成的Fisherfaces更专注于区分不同的人脸。

### 基于机器学习的分类器

#### KNN

#### SVM

#### 决策树

## 检测和追踪 Detection and Tracking

不同于目标识别(Object Regconition)，目标检测(Object Detection)并非图片层面。前者只关注一张图片中是否包含某种特定类别物体即可，而后者不仅识别图像中是否存在特定物体，还要确定物体的位置和大小，通常以边界框的形式表示，例如在一张图片中同时检测人、车、猫等。

至于目标追踪(Object Tracking)，则是指在连续的视频帧中跟踪特定物体的过程。此外，目标追踪可以在不识别出场景中物品的前提下，仅依靠动作特点识别。关于二者的区别，可以参考Quora的讨论[What is the difference between object detection and object tracking?](https://www.quora.com/What-is-the-difference-between-object-detection-and-object-tracking)。

### 目标检测

![时间轴线图](https://img-blog.csdnimg.cn/280feeef699349399f84b3ca40fecb1d.jpeg#pic_center)

整个目标检测技术的发展历史如上图所示。这些方法可按2012年AlexNet的出现前后分成传统方法和深度学习方法。其中，传统方法主要分为基于特征和基于分割两类。前者通过诸如Harr、HoG和SIFT等特征来找到目标对象，后者则通过检测边缘或区域来实现。对于基于特征的目标检测方法来说，它大体上可将步骤按下图划分。

![基于特征的传统方法流程](https://img-blog.csdnimg.cn/c10b2e7fd04c4ef4bc38d36ae431f0ca.jpeg#pic_center)

2012年之后随着算力及数据的提升，大量的深度学习模型涌现。最开始的模型主要采用的是以RCNN为首的two-stage目标检测模型。但随着移动端对目标检测效率要求的提高，16年之后模型开始往以YOLO为首的one-stage模型发展。但前面两种模型都比较依赖anchor的设定，即预先定义的边界框。这两类一并被称为anchor-based目标检测方法，其特点就是在同一像素点上生成多个不同大小和比例的候选框

因此，为减少anchor对模型的影响，18年以后开始兴起了对以CornerNet为首的anchor-free研究。17年底谷歌推出了Transformers模型，随后在19年开始大火并快速地应用于CV领域。在20年时，Facebook AI团队首次将Transformers模型应用于目标检测领域，开启了目标检测新的研究浪潮。

#### VJ and HoG+SVM

2004年Paul Viola和MichaelJones在CVPR上发表了一篇跨时代意义的文章《Robust Real-Time Face Detection》，后人将文章中的人脸检测算法称之为VJ算法。它极为有限的计算资源下第一次实现了人脸的实时检测，速度是同期检测算法的几十甚至上百倍，极大程度地推动了人脸检测应用商业化的进程。

具体来说，VJ算法由三个核心步骤组成，即Haar-like特征和积分图、Adaboost分类器和级联分类器。

#### DPM

(Deformable Part Model, DPM)

#### R-CNN

区域卷积神经网络(Region-CNN, R-CNN)是第一个将深度学习应用到目标检测的算法。它整体上类似基于特征的传统方法，同样是生成提取框，对每个框提取特征、图像分类、非极大值抑制四个步骤进行目标检测。只不过在提取特征这一步，将传统的特征方法(如SIFT、HoG等)换成了深度卷积网络。

具体来说，R-CNN首先使用Selective Search方法生成大约2000个大小不同的提取框。接着，使用AlexNet对每一个提取框进行特征提取，并将这些提取到的特征交给SVM分类器判断，得到每个区域中每个物品类别的概率。最后，使用非极大值抑制(Non Maxium Supperssion, NMS)方法来剔除冗余和重叠的候选区，最终得到每一个类别得分最高一些区域。

其中，Selective Search是一种候选区域生成方法(Region Proposal Algorithm)

后续Fast RCNN则使用(Region Proposal Network, RPN)

#### YOLO and SSD

YOLO(You Only Look Once)是由Joseph Redmon等人在2015年提出的一种快速、高效的目标检测算法。相比于R-CNN这类二阶段算法，YOLO不需要滑动窗口依次判定而是直接对整张图像进行目标检测和分类，并输出每个目标框的位置和类别概率。

### 目标追踪

#### 光流法

#### 卡尔曼滤波器

## 其他

### 连通域分析

### 阈值处理

## 参考

- [UIUC cs543 Computer Vision](https://courses.engr.illinois.edu/cs543/sp2015/)
- [Princeton COS 429 - Computer Vision](https://www.cs.princeton.edu/courses/archive/fall17/cos429/cos429.html)
- [浙江大学计算机视觉](https://qsctech.github.io/zju-icicles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/)
